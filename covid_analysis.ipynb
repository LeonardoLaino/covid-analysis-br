{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Projeto, Data Understanding & Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Definição do Projeto & Motivação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No dia 05/05/2023 a Organização Mundial da Saúde (OMS) declarou o fim da Emergência de Saúde Pública de Importância Internacional referente à COVID-19. [Fonte :OMS](https://www.paho.org/pt/noticias/5-5-2023-oms-declara-fim-da-emergencia-saude-publica-importancia-internacional-referente). \n",
    ">\n",
    "> Este anúncio traz alivio e fim a 3 longos anos, marcados por muita incerteza, perdas e mudanças talvez incomensuráveis na sociedade e no relacionamento humano.\n",
    ">\n",
    "> `Este projeto visa analisar os dados da COVID 19 no Brasil e extrair insights de como a mesma se comportou no país nos últimos 3 anos.`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Sobre os Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Neste projeto, irei utilizar os dados coletados e compilados pelo Centro de Ciência de Sistemas e Engenharia da universidade americana **John Hopkins** ([link](https://www.jhu.edu)). Os dados são atualizados diariamente deste janeiro de 2020 com uma granularidade temporal de dias e geográfica de regiões de países (estados, condados, etc.). O site do projeto pode ser acessado neste [link](https://systems.jhu.edu/research/public-health/ncov/) enquanto os dados, neste [link](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports). Abaixo estão descritos os dados derivados do seu processamento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **date**: data de referência;\n",
    " - **state**: estado;\n",
    " - **country**: país; \n",
    " - **population**: população estimada;\n",
    " - **confirmed**: número acumulado de infectados;\n",
    " - **confirmed_1d**: número diário de infectados;\n",
    " - **confirmed_moving_avg_7d**: média móvel de 7 dias do número diário de infectados;\n",
    " - **confirmed_moving_avg_7d_rate_14d**: média móvel de 7 dias dividido pela média móvel de 7 dias de 14 dias atrás;\n",
    " - **deaths**: número acumulado de mortos;\n",
    " - **deaths_1d**: número diário de mortos;\n",
    " - **deaths_moving_avg_7d**: média móvel de 7 dias do número diário de mortos;\n",
    " - **deaths_moving_avg_7d**: média móvel de 7 dias dividido pela média móvel de 7 dias de 14 dias atrás;\n",
    " - **month**: mês de referência;\n",
    " - **year**: ano de referência."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 - Sobre o Autor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Olá!\n",
    ">\n",
    "> Me chamo Leonardo, sou estudante do último ano de Engenharia Mecânica que tem como objetivo profissional migrar para a área de dados. Durante os anos de faculdade, trabalhei durante 2 anos com pesquisa na área aeroespacial (lançadores de satélite) no Instituto de Aeronáutica e Espaço, em São José dos Campos (IAE-DCTA). Lá tive meu primeiro contato com a programação e com dados (maioria proveniente de sensores acoplados aos foguetes) e, unindo essa experiencia com meu interesse pelas aulas de estatística durante a graduação, acabei conhecendo a área de ciencia de dados e me apaixonando."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta, datetime\n",
    "from typing import Iterator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extração dos Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Os dados estão salvos no formato `.csv`, onde cada arquivo corresponde a um dia do ano."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Criando um `Generator` para criar nosso `Iterator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_range(data_inicial: datetime, data_final: datetime) -> Iterator:\n",
    "    # Calculando a quantidade de dias\n",
    "    days_range = (data_final - data_inicial).days\n",
    "\n",
    "    # Criando o Iterator\n",
    "    for lag in range(days_range):\n",
    "        yield data_inicial + timedelta(lag)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Setando a data inicial e final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inicial = datetime(2021, 1, 1)\n",
    "data_final = datetime(2023, 1, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extraindo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para salvar as datas que não foram carregadas\n",
    "failed = list()\n",
    "\n",
    "# Objeto para criar o data frame Pandas\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Iterando sob todas as datas entre o intervalo que queremos considerar\n",
    "for date in date_range(data_inicial = data_inicial, data_final = data_final):\n",
    "    # Convertendo a data para string\n",
    "    date_str = date.strftime('%m-%d-%Y')\n",
    "\n",
    "    # Acessando o .csv através da url\n",
    "    source_url = f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{date_str}.csv'\n",
    "\n",
    "    \n",
    "    try: # Tenta acessar o arquivo referente à data da iteração atual\n",
    "\n",
    "        case = pd.read_csv(source_url, sep=',')\n",
    "\n",
    "    except: # Caso dê algum erro (possivelmente o arquivo não exista)\n",
    "\n",
    "        failed.append(date_str)\n",
    "        continue\n",
    "\n",
    "    else: # Caso consiga ler com sucesso o arquivo, adicionamos ao data frame\n",
    "\n",
    "        # Removendo as colunas que não iremos utilizar\n",
    "        case = case.drop(['FIPS', 'Admin2', 'Last_Update', 'Lat', 'Long_', 'Recovered', 'Active', 'Combined_Key', 'Case_Fatality_Ratio'], axis=1)\n",
    "        # Filtrando apenas os dados do Brasil\n",
    "        case = case.query('Country_Region == \"Brazil\"').reset_index(drop= True)\n",
    "        # Convertendo a coluna de Data\n",
    "        case['Date'] = pd.to_datetime(date.strftime('%Y-%m-%d'))\n",
    "        # Inserindo os dados dessa iteração ao data frame\n",
    "        df = pd.concat([df, case], axis= 0, ignore_index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
